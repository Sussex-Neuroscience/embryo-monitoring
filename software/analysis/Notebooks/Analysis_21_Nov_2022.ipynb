{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import copy\n",
    "\n",
    "import pandas\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import tqdm\n",
    "from scipy import signal\n",
    "from scipy.signal import find_peaks_cwt\n",
    "from matplotlib import rcParams\n",
    "from statsmodels.graphics.tsaplots import plot_acf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "class Analysis():\n",
    "    def __init__(self,filePath,grid_lenth):\n",
    "        self.filePath=filePath\n",
    "        self.lenth=0\n",
    "        self.datas=[]\n",
    "        self.data_columns=[]\n",
    "        self.hatching_points=[]\n",
    "        self.onset_points=[]\n",
    "        self.max_min_diff=[]\n",
    "        self.grid_lenth=grid_lenth\n",
    "        self.filtered_signals=[]\n",
    "        self.total_movements=[]\n",
    "        self.average_above_threshold=[]\n",
    "        self.durations=[]\n",
    "        self.moving_percentage=[]\n",
    "        self.average_bout=[]\n",
    "\n",
    "    def loading_datas(self):\n",
    "        for each_file in os.listdir(self.filePath):\n",
    "            if each_file.endswith(\".csv\"):\n",
    "                current=pd.read_csv(self.filePath + each_file)\n",
    "                self.datas.append(current)\n",
    "                self.data_columns.append(current.columns)\n",
    "        self.lenth =len(self.datas)\n",
    "\n",
    "    def knn_norm(self,data, k=7, mode=\"max\"):\n",
    "        lenth = len(data)\n",
    "        output_list = []\n",
    "        for i in range(lenth - k):\n",
    "            if mode == \"max\":\n",
    "                output_list.append((np.max(data[i:i + k])))\n",
    "            elif mode == \"mean\":\n",
    "                output_list.append((np.mean(data[i:i + k])))\n",
    "            elif mode == \"min\":\n",
    "                output_list.append((np.min(data[i:i + k])))\n",
    "\n",
    "        return np.hstack((np.ones(lenth-len(output_list))*output_list[0],np.array(output_list)))\n",
    "\n",
    "    def max_min_run(self):\n",
    "        for each_ in range(self.lenth):\n",
    "            diffs=[]\n",
    "            for j in tqdm.tqdm(range(self.grid_lenth)):\n",
    "                normBright = np.array(self.datas[each_][self.data_columns[each_][j]])\n",
    "                normBright_max = self.knn_norm(normBright, 60, \"max\")\n",
    "                normBright_min = self.knn_norm(normBright, 60, \"min\")\n",
    "                diff = normBright_max - normBright_min\n",
    "                diffs.append(copy.deepcopy(diff))\n",
    "            self.max_min_diff.append(diffs)\n",
    "\n",
    "\n",
    "    def hatching_onset_detection(self):\n",
    "        for each_ in range(self.lenth):\n",
    "            onset_point=[]\n",
    "            filtered_signals=[]\n",
    "            for j in tqdm.tqdm(range(self.grid_lenth)):\n",
    "                diff=self.max_min_diff[each_][j]\n",
    "                cut= diff[0:5000]\n",
    "                threshold= np.max(cut)\n",
    "                onset_point.append(np.where(diff>threshold)[0][0])\n",
    "                diff[np.where(diff<=threshold)[0]]=0\n",
    "                diff[np.where(diff>threshold)[0][0]]=0\n",
    "                filtered_signals.append(diff)\n",
    "            self.onset_points.append(onset_point)\n",
    "            self.filtered_signals.append(filtered_signals)\n",
    "\n",
    "    def hatching_complete_detection(self):\n",
    "        for each_ in range(self.lenth):\n",
    "            maxss=[]\n",
    "            for j in tqdm.tqdm(range(self.grid_lenth)):\n",
    "                ndiff=self.knn_norm(self.max_min_diff[each_][j],8000,\"mean\")\n",
    "                increase_point=np.where(ndiff>np.mean(ndiff)*1.2)[0][0]\n",
    "                cut=ndiff[:increase_point]\n",
    "                maxs =find_peaks_cwt(cut[10000:],500)\n",
    "                maxs+=10000\n",
    "                cuted=maxs[-2]\n",
    "                maxss.append((maxs[-2],maxs[-1]))\n",
    "                cut=cut[maxs[-2]:maxs[-1]]\n",
    "                mins =find_peaks_cwt(cut**-1,80)\n",
    "                predict=0\n",
    "                reverse_min = mins[::-1]\n",
    "                for i in range(len(mins)):\n",
    "                    if i ==0:\n",
    "                        continue\n",
    "                    else:\n",
    "                        if cut[reverse_min[i]] > cut[reverse_min[i-1]]:\n",
    "                            predict=reverse_min[i-1]+maxs[-2]\n",
    "                            #hatching_points.append(predict)\n",
    "                            break\n",
    "                if predict<(maxs[-2]+maxs[-1])/2:\n",
    "                    self.hatching_points[each_].append(int((maxs[-1]+(maxs[-2]+maxs[-1])/2)/2))\n",
    "                else:\n",
    "                    self.hatching_points[each_].append(predict)\n",
    "\n",
    "    def total_movement_quantity(self):\n",
    "        self.total_movements=[]\n",
    "        for each_ in range(self.lenth):\n",
    "            Sum_above_threshold=[]\n",
    "            for i in tqdm.tqdm(range(self.grid_lenth)):\n",
    "                Sum_above_threshold.append(len(np.where(self.filtered_signals[each_][i][self.onset_points[each_][i]:self.hatching_points[each_][i]]!=0)[0]))\n",
    "            self.total_movements.append(Sum_above_threshold)\n",
    "\n",
    "    def average_movement_magnitude(self):\n",
    "        for each_ in range(self.lenth):\n",
    "            Average_of_values=[]\n",
    "            for i in tqdm.tqdm(range(self.grid_lenth)):\n",
    "                Average_of_values.append(np.average(self.datas[each_][self.data_columns[each_][i]][np.where(self.filtered_signals[each_][i][self.onset_points[each_][i]:self.hatching_points[each_][i]]!=0)[0]]))\n",
    "            self.average_above_threshold.append(Average_of_values)\n",
    "\n",
    "    def calculate_durations(self):\n",
    "        for each_ in range(self.lenth):\n",
    "            Duration=[]\n",
    "            for i in tqdm.tqdm(range(self.grid_lenth)):\n",
    "                Duration.append(len(self.filtered_signals[each_][i][self.onset_points[each_][i]:self.hatching_points[each_][i]]))\n",
    "            self.durations.append(Duration)\n",
    "\n",
    "    def calculate_moving_percentage(self):\n",
    "        for each_ in range(self.lenth):\n",
    "            Moving_Percentage=[]\n",
    "            for i in tqdm.tqdm(range(self.grid_lenth)):\n",
    "                Moving_Percentage.append(len(np.where(self.filtered_signals[each_][i][self.onset_points[each_][i]:self.hatching_points[each_][i]]!=0)[0])/len(self.filtered_signals[each_][i]))\n",
    "            self.moving_percentage.append(Moving_Percentage)\n",
    "\n",
    "    def calculate_average_bout(self):\n",
    "        for each_ in range(self.lenth):\n",
    "            Average_bout=[]\n",
    "            for i in tqdm.tqdm(range(self.grid_lenth)):\n",
    "                pos = np.where(self.filtered_signals[each_][i] > 0)[0]\n",
    "                split = np.where(np.diff(pos) != 1)[0] + 1\n",
    "                arr=np.split(self.filtered_signals[each_][i][pos],split)\n",
    "                lenths=[]\n",
    "                for j in arr:\n",
    "                    lenths.append(len(j))\n",
    "                Average_bout.append(np.mean(lenths))\n",
    "            self.average_bout.append(Average_bout)\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [
    "filePath = \"../../data/\"\n",
    "#fileName = \"output2022-04-27T15_16_04.csv\"\n",
    "fileName = \"Raw1.csv\""
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 24/24 [00:13<00:00,  1.75it/s]\n",
      "100%|██████████| 24/24 [00:00<00:00, 3425.09it/s]\n"
     ]
    }
   ],
   "source": [
    "test1=Analysis(filePath,24)\n",
    "test1.loading_datas()\n",
    "test1.max_min_run()\n",
    "test1.hatching_onset_detection()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "data": {
      "text/plain": "[[12638,\n  6325,\n  10480,\n  6251,\n  8481,\n  15360,\n  9285,\n  7129,\n  5026,\n  5494,\n  7724,\n  5623,\n  5260,\n  5331,\n  11453,\n  14128,\n  6577,\n  6595,\n  7962,\n  14035,\n  11625,\n  5685,\n  9352,\n  6959]]"
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test1.onset_points"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}